{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01: Linear Algebra Intro\n",
    "\n",
    "Welcome to your first deep dive! Today we‚Äôll build intuition and hands-on experience with vectors, matrices, and their operations‚Äîthe foundation of almost every ML algorithm.\n",
    "\n",
    "> üí° **Companion Reading**: This notebook pairs with [01_linear_algebra_intro.md](01_linear_algebra_intro.md) for deeper mathematical insights, analogies, and tutor guidance.\n",
    "\n",
    "## üéØ Objectives\n",
    "- Understand what vectors and matrices are conceptually and computationally\n",
    "- Learn how to compute dot products and matrix multiplication\n",
    "- Visualize geometric interpretations of linear transformations\n",
    "- Explore how these concepts relate to ML models\n",
    "- Build intuition through hands-on coding and visualization\n"
   ],
   "id": "3a1723715fb88362"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üéØ Understanding Vectors: The Foundation of Machine Learning\n",
    "\n",
    "Before we dive into operations, let's build a deep understanding of **what vectors are** and **why they're absolutely central** to machine learning.\n",
    "\n",
    "### What Are Vectors?\n",
    "\n",
    "A **vector** is much more than just \"a list of numbers.\" It's a mathematical object that represents:\n",
    "- **Magnitude** (how big/long it is)\n",
    "- **Direction** (which way it points)\n",
    "- **Position in space** (where it lives in multi-dimensional space)\n",
    "\n",
    "Think of vectors as **arrows in space** that encode information about data, relationships, and transformations.\n",
    "\n",
    "### Why Vectors Are Central to Machine Learning\n",
    "\n",
    "**Every piece of data in ML becomes a vector:**\n",
    "- üì∏ **Images**: Each pixel's color values ‚Üí vector of intensities\n",
    "- üìù **Text**: Word frequencies or embeddings ‚Üí vector representations  \n",
    "- üë§ **User profiles**: Age, income, preferences ‚Üí feature vectors\n",
    "- üéµ **Audio**: Frequency components over time ‚Üí signal vectors\n",
    "- üß¨ **DNA**: Nucleotide sequences ‚Üí biological feature vectors\n",
    "\n",
    "**All ML algorithms work by:**\n",
    "1. **Representing** data as vectors in high-dimensional spaces\n",
    "2. **Measuring** relationships between vectors (similarity, distance)\n",
    "3. **Transforming** vectors to find patterns and make predictions\n",
    "4. **Learning** optimal vector transformations from data\n",
    "\n",
    "Let's explore this with concrete examples!\n"
   ],
   "id": "3b49c5e9d7bcdd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example 1: Representing different types of data as vectors\n",
    "print(\"=== DATA AS VECTORS ===\")\n",
    "\n",
    "# A simple user profile as a vector [age, income_k, hours_online_per_day]\n",
    "user1 = np.array([25, 45, 3])  # 25 years old, $45k income, 3 hours online\n",
    "user2 = np.array([35, 75, 1])  # 35 years old, $75k income, 1 hour online\n",
    "user3 = np.array([22, 35, 8])  # 22 years old, $35k income, 8 hours online\n",
    "\n",
    "print(\"User profiles as vectors:\")\n",
    "print(f\"User 1: {user1} (age, income_k, hours_online)\")\n",
    "print(f\"User 2: {user2}\")\n",
    "print(f\"User 3: {user3}\")\n",
    "\n",
    "# Which users are most similar? We can measure this with vector similarity!\n",
    "similarity_1_2 = np.dot(user1, user2) / (np.linalg.norm(user1) * np.linalg.norm(user2))\n",
    "similarity_1_3 = np.dot(user1, user3) / (np.linalg.norm(user1) * np.linalg.norm(user3))\n",
    "\n",
    "print(f\"\\nSimilarity between User 1 and User 2: {similarity_1_2:.3f}\")\n",
    "print(f\"Similarity between User 1 and User 3: {similarity_1_3:.3f}\")\n",
    "print(\"Higher values mean more similar users!\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT NOTE ABOUT THESE RESULTS:\")\n",
    "print(\"These similarity scores aren't very meaningful yet because our data\")\n",
    "print(\"has different scales: age (20-40), income (30k-80k), hours (1-8).\")\n",
    "print(\"The income values dominate the calculation!\")\n",
    "print(\"We'll learn about 'normalization' below to fix this problem.\")\n"
   ],
   "id": "2a297026b31cd74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visual Understanding: Vectors as Arrows\n",
    "\n",
    "Let's visualize vectors to build geometric intuition:\n"
   ],
   "id": "6c2f7b41a04445f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a comprehensive vector visualization\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax4 = plt.subplot(2, 2, 4, projection='3d')\n",
    "\n",
    "# Plot 1: Basic vector representation\n",
    "v1 = np.array([3, 4])\n",
    "v2 = np.array([1, 3])\n",
    "ax1.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1,\n",
    "           color='blue', width=0.01, label=f'v1 = {v1}')\n",
    "ax1.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1,\n",
    "           color='red', width=0.01, label=f'v2 = {v2}')\n",
    "ax1.set_xlim(-1, 5)\n",
    "ax1.set_ylim(-1, 5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_title('Vectors as Arrows in Space')\n",
    "ax1.set_xlabel('X dimension')\n",
    "ax1.set_ylabel('Y dimension')\n",
    "\n",
    "# Add magnitude annotations\n",
    "ax1.annotate(f'|v1| = {np.linalg.norm(v1):.1f}', xy=(1.5, 2), fontsize=10)\n",
    "ax1.annotate(f'|v2| = {np.linalg.norm(v2):.1f}', xy=(0.5, 1.5), fontsize=10)\n",
    "\n",
    "# Plot 2: Angles between vectors\n",
    "\n",
    "# Compute angle between vectors\n",
    "dot_product = np.dot(v1, v2)\n",
    "norm_v1 = np.linalg.norm(v1)\n",
    "norm_v2 = np.linalg.norm(v2)\n",
    "angle = np.arccos(dot_product / (norm_v1 * norm_v2))\n",
    "\n",
    "# Determine direction using cross product\n",
    "cross = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "if cross < 0:\n",
    "    angle = -angle  # Clockwise\n",
    "\n",
    "# Set radius\n",
    "r = 0.5\n",
    "\n",
    "# Compute angle of the first vector\n",
    "theta1 = np.arctan2(v1[1], v1[0])\n",
    "\n",
    "# Generate the arc\n",
    "theta = np.linspace(theta1, theta1 + angle, 50)\n",
    "x = r * np.cos(theta)\n",
    "y = r * np.sin(theta)\n",
    "\n",
    "ax2.plot(x, y, color='green', label='Arc Between Vectors')\n",
    "ax2.text(-0.4, -0.4, f'Œ∏ = {np.degrees(angle):.1f}¬∞', fontsize=12, color='green')\n",
    "\n",
    "ax2.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1,\n",
    "           color='blue', width=0.01, label='v1')\n",
    "ax2.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1,\n",
    "           color='red', width=0.01, label='v2')\n",
    "ax2.set_xlim(-1, 5)\n",
    "ax2.set_ylim(-1, 5)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "ax2.set_title('Angle Between Vectors')\n",
    "ax2.set_xlabel('X dimension')\n",
    "ax2.set_ylabel('Y dimension')\n",
    "\n",
    "# Plot 3: Different vector relationships\n",
    "vectors = {\n",
    "    'Same direction': ([2, 1], [4, 2], 'green'),\n",
    "    'Perpendicular': ([1, 0], [0, 1], 'orange'),\n",
    "    'Opposite': ([1, 1], [-1, -1], 'purple')\n",
    "}\n",
    "\n",
    "colors = ['green', 'orange', 'purple']\n",
    "for i, (label, (v_a, v_b, color)) in enumerate(vectors.items()):\n",
    "    ax3.quiver(0, 0, v_a[0], v_a[1], angles='xy', scale_units='xy', scale=1,\n",
    "               color=color, width=0.008, alpha=0.7)\n",
    "    ax3.quiver(0, 0, v_b[0], v_b[1], angles='xy', scale_units='xy', scale=1,\n",
    "               color=color, width=0.008, alpha=0.7, linestyle='--')\n",
    "\n",
    "    # Calculate and display dot product\n",
    "    dot_prod = np.dot(v_a, v_b)\n",
    "    ax3.text(-2, 2 - i * 0.5, f'{label}: dot = {dot_prod}', color=color, fontsize=10)\n",
    "\n",
    "ax3.set_xlim(-2, 5)\n",
    "ax3.set_ylim(-2, 3)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_title('Vector Relationships & Dot Products')\n",
    "ax3.set_xlabel('X dimension')\n",
    "ax3.set_ylabel('Y dimension')\n",
    "\n",
    "# Plot 4: ML Application - Document similarity (3D visualization)\n",
    "# Simulate word frequency vectors for documents\n",
    "doc1 = np.array([6, 0, 4])  # [freq_of_'machine learning', 'cooking', 'algorithm']\n",
    "doc2 = np.array([8, 0, 5])  # Similar document about ML\n",
    "doc3 = np.array([0, 4, 0])  # Document about cooking\n",
    "\n",
    "# Calculate similarities\n",
    "sim_1_2 = np.dot(doc1, doc2) / (np.linalg.norm(doc1) * np.linalg.norm(doc2))\n",
    "sim_1_3 = np.dot(doc1, doc3) / (np.linalg.norm(doc1) * np.linalg.norm(doc3))\n",
    "\n",
    "# Visualize in full 3D space (all three dimensions)\n",
    "ax4.scatter(doc1[0], doc1[1], doc1[2], s=100, color='blue', label='ML Doc 1', alpha=0.8)\n",
    "ax4.scatter(doc2[0], doc2[1], doc2[2], s=100, color='green', label='ML Doc 2', alpha=0.8)\n",
    "ax4.scatter(doc3[0], doc3[1], doc3[2], s=100, color='red', label='Cooking Doc', alpha=0.8)\n",
    "\n",
    "# Draw similarity lines in 3D\n",
    "ax4.plot([doc1[0], doc2[0]], [doc1[1], doc2[1]], [doc1[2], doc2[2]], \n",
    "         'purple', alpha=0.6, linewidth=2, label=f'ML Similarity: {sim_1_2:.3f}')\n",
    "ax4.plot([doc1[0], doc3[0]], [doc1[1], doc3[1]], [doc1[2], doc3[2]], \n",
    "         'yellow', alpha=0.6, linewidth=2, label=f'Cross-domain: {sim_1_3:.3f}')\n",
    "\n",
    "# Add text annotations for document vectors\n",
    "ax4.text(doc1[0], doc1[1], doc1[2]+0.2, f'[{doc1[0]},{doc1[1]},{doc1[2]}]', fontsize=8)\n",
    "ax4.text(doc2[0], doc2[1], doc2[2]+0.2, f'[{doc2[0]},{doc2[1]},{doc2[2]}]', fontsize=8)\n",
    "ax4.text(doc3[0], doc3[1], doc3[2]+0.2, f'[{doc3[0]},{doc3[1]},{doc3[2]}]', fontsize=8)\n",
    "\n",
    "ax4.set_xlim(0, 8)\n",
    "ax4.set_ylim(0, 4)\n",
    "ax4.set_zlim(0, 3)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend(loc='upper left', fontsize=9)\n",
    "ax4.set_title('ML Application: Document Similarity (3D)', fontsize=11)\n",
    "ax4.set_xlabel('Frequency of \"machine learning\"')\n",
    "ax4.set_ylabel('Frequency of \"cooking\"')\n",
    "ax4.set_zlabel('Frequency of \"algorithm\"')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"‚Ä¢ Vectors encode both magnitude (length) and direction\")\n",
    "print(\"‚Ä¢ Angle between vectors measures their similarity/relationship\")\n",
    "print(\"‚Ä¢ Small angles = high similarity, large angles = low similarity\")\n",
    "print(\"‚Ä¢ 3D visualization shows ALL dimensions, not just projections\")\n",
    "print(\"‚Ä¢ Document vectors: ML docs cluster together, cooking doc is distant\")\n",
    "print(\"‚Ä¢ Algorithm frequency (3rd dimension) adds important context!\")\n",
    "print(\"‚Ä¢ ML algorithms use these geometric relationships to find patterns!\")\n",
    "\n"
   ],
   "id": "bfd631fa3ef2dd43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üéØ Why Do Vectors Start at the Origin?\n",
    "\n",
    "You might have noticed that in all our visualizations, vectors start at the origin (0,0). Let's explore **why** this is the case and **whether it's always necessary**.\n",
    "\n",
    "#### The Mathematical Reasoning\n",
    "\n",
    "**In our examples, vectors start at the origin (0,0) for practical reasons:**\n",
    "- **Standard reference point**: Creates consistency for all vector operations\n",
    "- **Teaching clarity**: Makes coordinates and position relationship obvious\n",
    "- **Simplified calculations**: Coordinates directly give vector components\n",
    "\n",
    "#### Is the Origin Always (0,0)?\n",
    "\n",
    "**No!** Vectors can start from any point. Let's demonstrate this with code:\n"
   ],
   "id": "4c785addb5ae8f43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Demonstrate that vectors represent displacement, not absolute position\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Same vector [3, 4] starting from different points\n",
    "vector_displacement = np.array([3, 4])\n",
    "\n",
    "# Starting points\n",
    "start_points = [\n",
    "    (0, 0),  # Origin\n",
    "    (2, 1),  # Different starting point\n",
    "    (5, 3),  # Another starting point\n",
    "]\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "labels = ['From origin (0,0)', 'From point (2,1)', 'From point (5,3)']\n",
    "\n",
    "# Plot 1: Same vector from different starting points\n",
    "for i, (start_x, start_y) in enumerate(start_points):\n",
    "    end_x = start_x + vector_displacement[0]\n",
    "    end_y = start_y + vector_displacement[1]\n",
    "\n",
    "    ax1.quiver(start_x, start_y, vector_displacement[0], vector_displacement[1], \n",
    "               angles='xy', scale_units='xy', scale=1, \n",
    "               color=colors[i], width=0.008, label=labels[i])\n",
    "\n",
    "    # Mark start and end points\n",
    "    ax1.plot(start_x, start_y, 'o', color=colors[i], markersize=8, alpha=0.7)\n",
    "    ax1.plot(end_x, end_y, 's', color=colors[i], markersize=8, alpha=0.7)\n",
    "\n",
    "    # Add text annotations\n",
    "    ax1.annotate(f'Start: ({start_x},{start_y})', \n",
    "                xy=(start_x, start_y), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=9, color=colors[i])\n",
    "    ax1.annotate(f'End: ({end_x},{end_y})', \n",
    "                xy=(end_x, end_y), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=9, color=colors[i])\n",
    "\n",
    "ax1.set_xlim(-1, 9)\n",
    "ax1.set_ylim(-1, 8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_title('Same Vector [3,4] from Different Starting Points')\n",
    "ax1.set_xlabel('X dimension')\n",
    "ax1.set_ylabel('Y dimension')\n",
    "\n",
    "# Plot 2: Demonstrate that all vectors have same magnitude and direction\n",
    "ax2.text(0.1, 0.9, 'All vectors represent the same displacement:', \n",
    "         transform=ax2.transAxes, fontsize=12, weight='bold')\n",
    "\n",
    "for i, (start_x, start_y) in enumerate(start_points):\n",
    "    magnitude = np.linalg.norm(vector_displacement)\n",
    "    direction = np.degrees(np.arctan2(vector_displacement[1], vector_displacement[0]))\n",
    "\n",
    "    ax2.text(0.1, 0.8 - i*0.15, f'{labels[i]}:', \n",
    "             transform=ax2.transAxes, fontsize=11, color=colors[i], weight='bold')\n",
    "    ax2.text(0.1, 0.75 - i*0.15, f'  ‚Ä¢ Magnitude: {magnitude:.1f}', \n",
    "             transform=ax2.transAxes, fontsize=10, color=colors[i])\n",
    "    ax2.text(0.1, 0.7 - i*0.15, f'  ‚Ä¢ Direction: {direction:.1f}¬∞', \n",
    "             transform=ax2.transAxes, fontsize=10, color=colors[i])\n",
    "\n",
    "ax2.text(0.1, 0.3, 'Key Insight: The vector [3,4] represents the same\\n\"move 3 right, 4 up\" regardless of starting point!', \n",
    "         transform=ax2.transAxes, fontsize=11, \n",
    "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== UNDERSTANDING VECTOR ORIGINS ===\")\n",
    "print(\"‚úì Vectors represent DISPLACEMENT, not absolute position\")\n",
    "print(\"‚úì The same vector [3,4] has identical magnitude and direction regardless of starting point\")\n",
    "print(\"‚úì We use origin (0,0) in examples for:\")\n",
    "print(\"  ‚Ä¢ Teaching clarity\")\n",
    "print(\"  ‚Ä¢ Mathematical convenience\") \n",
    "print(\"  ‚Ä¢ Standard convention\")\n",
    "print(\"‚úì In real applications, vectors can start from any point!\")\n"
   ],
   "id": "c3de88519cdea668",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Real-World Applications: Vectors Beyond the Origin\n",
    "\n",
    "Examples where vectors DON'T start at (0,0):\n",
    "\n",
    "üöó **Physics - Car velocity:**\n",
    "- A car at position (100, 50) moving with velocity [20, 10]\n",
    "- The velocity vector starts from the car's current position\n",
    "\n",
    "üéÆ **Computer Graphics - Object movement:**\n",
    "- A game character at (x, y) moving with direction vector [dx, dy]\n",
    "- Movement vector starts from character's current location\n",
    "\n",
    "üß† **Machine Learning - Feature vectors:**\n",
    "- User profile [age=25, income=50k] in feature space\n",
    "- The 'origin' might represent average values, not (0,0)\n",
    "\n",
    "üí° **Key Takeaway:**\n",
    "- Vectors are about DIRECTION and MAGNITUDE, not starting position!\n",
    "- We use (0,0) in tutorials for simplicity, but vectors work from any point.\n"
   ],
   "id": "37c50edee0dff30d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÑ Vector Comparison: Same vs Different Starting Points\n",
    "\n",
    "**Are vectors always compared to the same starting point?** No! The comparison approach depends on what you're trying to measure.\n",
    "\n",
    "#### When Vectors Share the Same Starting Point\n",
    "- **Purpose**: Compare directions and magnitudes directly\n",
    "- **Examples**: User preferences, force analysis, data similarity\n",
    "\n",
    "#### When Vectors Have Different Starting Points  \n",
    "- **Purpose**: Compare relative movements or changes\n",
    "- **Examples**: Navigation, stock changes, game movements\n",
    "\n",
    "Let's explore this with concrete examples:\n"
   ],
   "id": "1cd769c84f44b44c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Demonstrate vector comparison scenarios\n",
    "print(\"=== VECTOR COMPARISON SCENARIOS ===\")\n",
    "print()\n",
    "\n",
    "# Scenario 1: Same starting point - User profiles (building on our earlier example)\n",
    "print(\"üéØ SAME STARTING POINT - User Profiles:\")\n",
    "# Let's use normalized versions of our user data for fair comparison\n",
    "user_a_norm = np.array([0.5, 0.6, 0.3])  # [age_norm, income_norm, hours_norm]\n",
    "user_b_norm = np.array([0.7, 0.9, 0.1])  # Normalized to 0-1 scale\n",
    "\n",
    "similarity = np.dot(user_a_norm, user_b_norm) / (np.linalg.norm(user_a_norm) * np.linalg.norm(user_b_norm))\n",
    "print(f\"   User A (normalized): {user_a_norm} (age, income, hours_online)\")\n",
    "print(f\"   User B (normalized): {user_b_norm}\")\n",
    "print(f\"   Similarity score: {similarity:.3f}\")\n",
    "print(\"   ‚Üí Both start from [0,0,0] baseline to compare profiles directly\")\n",
    "print()\n",
    "\n",
    "# Scenario 2: Different starting points - Navigation\n",
    "print(\"üó∫Ô∏è DIFFERENT STARTING POINTS - Navigation:\")\n",
    "person_a_location = np.array([10, 20])\n",
    "person_b_location = np.array([50, 60])\n",
    "store_location = np.array([15, 23])\n",
    "\n",
    "vector_a = store_location - person_a_location  # Direction to store from A\n",
    "vector_b = store_location - person_b_location  # Direction to store from B\n",
    "\n",
    "print(f\"   Person A at {person_a_location} ‚Üí Store: vector {vector_a}\")\n",
    "print(f\"   Person B at {person_b_location} ‚Üí Store: vector {vector_b}\")\n",
    "print(\"   ‚Üí Same destination, different starting points = different vectors\")\n",
    "print()\n",
    "\n",
    "# Scenario 3: Same starting point - User behavior changes over time\n",
    "print(\"üìà SAME STARTING POINT - User Behavior Changes:\")\n",
    "user_a_changes = np.array([0.1, -0.05, 0.15])   # Changes in online hours (normalized)\n",
    "user_b_changes = np.array([0.05, 0.1, -0.05])   # Changes in online hours (normalized)\n",
    "\n",
    "correlation = np.corrcoef(user_a_changes, user_b_changes)[0,1]\n",
    "print(f\"   User A changes: {user_a_changes} (Month 1, 2, 3 online hours)\")\n",
    "print(f\"   User B changes: {user_b_changes}\")\n",
    "print(f\"   Correlation: {correlation:.3f}\")\n",
    "print(\"   ‚Üí Both start from 0 baseline to compare behavior patterns\")\n",
    "print()\n",
    "\n",
    "# Scenario 4: Different starting points - Game physics\n",
    "print(\"üéÆ DIFFERENT STARTING POINTS - Game Physics:\")\n",
    "player1_pos = np.array([100, 200])\n",
    "player2_pos = np.array([300, 400])\n",
    "movement = np.array([10, 0])  # Both move right\n",
    "\n",
    "print(f\"   Player 1 at {player1_pos} moves by {movement}\")\n",
    "print(f\"   Player 2 at {player2_pos} moves by {movement}\")\n",
    "print(\"   ‚Üí Same movement vector, different starting positions\")\n"
   ],
   "id": "6ecb6c6f14051e3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize the comparison scenarios\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Same starting point - User profiles (normalized)\n",
    "categories = ['Age', 'Income', 'Hours Online']\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x_pos - width/2, user_a_norm, width, label='User A', alpha=0.8, color='blue')\n",
    "ax1.bar(x_pos + width/2, user_b_norm, width, label='User B', alpha=0.8, color='red')\n",
    "ax1.set_xlabel('User Profile Features (Normalized)')\n",
    "ax1.set_ylabel('Normalized Value (0-1)')\n",
    "ax1.set_title('Same Starting Point: User Profiles')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(categories)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Different starting points - Navigation\n",
    "ax2.scatter(*person_a_location, s=100, color='blue', label='Person A', marker='o')\n",
    "ax2.scatter(*person_b_location, s=100, color='red', label='Person B', marker='o')\n",
    "ax2.scatter(*store_location, s=150, color='green', label='Store', marker='s')\n",
    "\n",
    "# Draw vectors to store\n",
    "ax2.quiver(person_a_location[0], person_a_location[1], vector_a[0], vector_a[1], \n",
    "           angles='xy', scale_units='xy', scale=1, color='blue', width=0.005)\n",
    "ax2.quiver(person_b_location[0], person_b_location[1], vector_b[0], vector_b[1], \n",
    "           angles='xy', scale_units='xy', scale=1, color='red', width=0.005)\n",
    "\n",
    "ax2.set_xlabel('X Position')\n",
    "ax2.set_ylabel('Y Position')\n",
    "ax2.set_title('Different Starting Points: Navigation')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Same starting point - User behavior changes\n",
    "months = ['Month 1', 'Month 2', 'Month 3']\n",
    "ax3.plot(months, user_a_changes, 'o-', label='User A', linewidth=2, markersize=8)\n",
    "ax3.plot(months, user_b_changes, 's-', label='User B', linewidth=2, markersize=8)\n",
    "ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Time Period')\n",
    "ax3.set_ylabel('Change in Online Hours (Normalized)')\n",
    "ax3.set_title('Same Starting Point: User Behavior Changes')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Different starting points - Game physics\n",
    "ax4.scatter(*player1_pos, s=100, color='blue', label='Player 1', marker='o')\n",
    "ax4.scatter(*player2_pos, s=100, color='red', label='Player 2', marker='o')\n",
    "\n",
    "# Show movement vectors\n",
    "ax4.quiver(player1_pos[0], player1_pos[1], movement[0], movement[1], \n",
    "           angles='xy', scale_units='xy', scale=1, color='blue', width=0.005)\n",
    "ax4.quiver(player2_pos[0], player2_pos[1], movement[0], movement[1], \n",
    "           angles='xy', scale_units='xy', scale=1, color='red', width=0.005)\n",
    "\n",
    "ax4.set_xlabel('X Position')\n",
    "ax4.set_ylabel('Y Position')\n",
    "ax4.set_title('Different Starting Points: Game Movement')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"‚úì Same starting point ‚Üí Compare directions/magnitudes directly\")\n",
    "print(\"‚úì Different starting points ‚Üí Compare relative movements/changes\")\n",
    "print(\"‚úì Choice depends on what you want to measure!\")\n",
    "print(\"‚úì ML often uses same starting point for data similarity\")\n",
    "print(\"‚úì Physics/navigation often use different starting points for movements\")\n",
    "print()\n",
    "print(\"üéØ BUILDING ON OUR USER PROFILE THEME:\")\n",
    "print(\"‚úì User profiles [age, income, hours_online] are our consistent example\")\n",
    "print(\"‚úì Normalization is crucial for fair comparisons between features\")\n",
    "print(\"‚úì Without normalization, income values dominate the similarity calculation\")\n",
    "print(\"‚úì All subsequent examples build on this user profile foundation\")\n"
   ],
   "id": "c77ad50e5288ff36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìå Vectors and Basic Operations\n",
    "Let's continue with our user profile theme and explore basic vector operations."
   ],
   "id": "2a3e1202d907efb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two user profiles (simplified to 2D for visualization)\n",
    "user_profile_1 = np.array([0.4, 0.6])  # [age_normalized, income_normalized]\n",
    "user_profile_2 = np.array([0.8, 0.3])  # Different user profile\n",
    "\n",
    "# Vector addition and scalar multiplication\n",
    "print(\"User Profile 1 + User Profile 2 =\", user_profile_1 + user_profile_2)\n",
    "print(\"2 * User Profile 1 =\", 2 * user_profile_1)\n",
    "print(\"\\nNote: Vector addition might represent combining user characteristics\")\n",
    "print(\"Scalar multiplication might represent scaling user features\")"
   ],
   "id": "f2ceff4a473845c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üî¢ Dot Product\n",
    "The dot product tells us how aligned two vectors are. Mathematically: **a** ¬∑ **b** = ||a|| ||b|| cos(Œ∏)\n",
    "\n",
    "**Breaking down this notation:**\n",
    "- **a** ¬∑ **b**: The dot product of vectors **a** and **b** (read as \"a dot b\")\n",
    "- **||a||**: The magnitude (length) of vector **a** (double pipes mean \"length of\")\n",
    "- **||b||**: The magnitude (length) of vector **b**\n",
    "- **cos(Œ∏)**: Cosine of the angle Œ∏ (theta) between the vectors\n",
    "- **Œ∏**: Greek letter representing the angle between vectors **a** and **b**\n",
    "\n",
    "This means:\n",
    "- When vectors point in the same direction (Œ∏ = 0¬∞): cos(0¬∞) = 1, maximum dot product\n",
    "- When vectors are perpendicular (Œ∏ = 90¬∞): cos(90¬∞) = 0, dot product = 0\n",
    "- When vectors point in opposite directions (Œ∏ = 180¬∞): cos(180¬∞) = -1, negative dot product\n"
   ],
   "id": "82f39fbf57fb4b51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute dot product between user profiles\n",
    "dot = np.dot(user_profile_1, user_profile_2)\n",
    "print(\"Dot product of user profiles:\", dot)\n",
    "\n",
    "# Let's explore the geometric meaning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the user profile vectors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.quiver(0, 0, user_profile_1[0], user_profile_1[1], angles='xy', scale_units='xy', scale=1, \n",
    "           color='blue', label='User 1 Profile', width=0.005)\n",
    "plt.quiver(0, 0, user_profile_2[0], user_profile_2[1], angles='xy', scale_units='xy', scale=1, \n",
    "           color='red', label='User 2 Profile', width=0.005)\n",
    "\n",
    "# Calculate angle between user profile vectors\n",
    "angle = np.arccos(dot / (np.linalg.norm(user_profile_1) * np.linalg.norm(user_profile_2)))\n",
    "print(f\"Angle between user profiles: {np.degrees(angle):.1f} degrees\")\n",
    "print(\"Smaller angles mean more similar users!\")\n",
    "\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-0.1, 1.0)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel('Age (normalized)')\n",
    "plt.ylabel('Income (normalized)')\n",
    "plt.title(f'User Profile Vectors (dot product = {dot:.3f})')\n",
    "plt.show()\n",
    "\n",
    "# Special case: dot product with itself gives squared magnitude\n",
    "profile1_squared = np.dot(user_profile_1, user_profile_1)\n",
    "profile1_magnitude_squared = np.linalg.norm(user_profile_1)**2\n",
    "print(f\"User Profile 1 ¬∑ User Profile 1 = {profile1_squared:.3f}\")\n",
    "print(f\"||User Profile 1||¬≤ = {profile1_magnitude_squared:.3f}\")\n",
    "print(\"They're equal! This is always true.\")\n"
   ],
   "id": "246ac61916e087e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Quiz:**\n",
    "What is the geometric meaning of a dot product?\n",
    "- A. The angle between vectors\n",
    "- B. The projection of one vector onto another  \n",
    "- C. A measure of similarity/alignment\n",
    "- D. All of the above\n",
    "\n",
    "> **Answer**: D. All of the above! The dot product encodes the angle between vectors, can be used to compute projections, and serves as a similarity measure.\n"
   ],
   "id": "66ddfebc035e2b85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìê Vector Projection: Hands-On Practice\n",
    "\n",
    "Now let's explore **vector projection** - one of the most important concepts in linear algebra and ML! \n",
    "\n",
    "Vector projection answers: \"How much of vector **a** lies in the direction of vector **b**?\"\n",
    "\n",
    "Think of it as the \"shadow\" that vector **a** casts onto vector **b** when light shines perpendicular to **b**.\n"
   ],
   "id": "d1f815b62e20581d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's compute and visualize vector projections\n",
    "def project_vector(a, b):\n",
    "    \"\"\"Project vector a onto vector b\"\"\"\n",
    "    # Scalar projection (length of the shadow)\n",
    "    scalar_proj = np.dot(a, b) / np.linalg.norm(b)\n",
    "\n",
    "    # Vector projection (the actual shadow vector)\n",
    "    vector_proj = (np.dot(a, b) / np.dot(b, b)) * b\n",
    "\n",
    "    return scalar_proj, vector_proj\n",
    "\n",
    "# Example: Project one user profile onto another\n",
    "user_a = np.array([0.6, 0.8])  # User A: [age_norm, income_norm]\n",
    "user_b = np.array([1.0, 0.0])  # Reference direction: pure age dimension\n",
    "\n",
    "scalar_proj, vector_proj = project_vector(user_a, user_b)\n",
    "\n",
    "print(\"=== USER PROFILE PROJECTION EXAMPLE ===\")\n",
    "print(f\"User A profile: {user_a} (age_norm, income_norm)\")\n",
    "print(f\"Reference direction: {user_b} (pure age dimension)\")\n",
    "print(f\"Scalar projection (age component): {scalar_proj:.2f}\")\n",
    "print(f\"Vector projection: {vector_proj}\")\n",
    "\n",
    "# Interpretation for ML\n",
    "print(f\"\\nML Interpretation:\")\n",
    "print(f\"User A's profile magnitude = {np.linalg.norm(user_a):.2f}\")\n",
    "print(f\"User A's 'age component' when projected onto age axis = {scalar_proj:.2f}\")\n",
    "print(\"This tells us how much of User A's profile is explained by age alone!\")\n"
   ],
   "id": "3018203b6df7e741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize the projection\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot original vectors\n",
    "plt.quiver(0, 0, user_a[0], user_a[1], angles='xy', scale_units='xy', scale=1, \n",
    "           color='blue', width=0.01, label=f'User A = {user_a}')\n",
    "plt.quiver(0, 0, user_b[0], user_b[1], angles='xy', scale_units='xy', scale=1, \n",
    "           color='red', width=0.01, label=f'Age axis = {user_b}')\n",
    "\n",
    "# Plot the projection\n",
    "plt.quiver(0, 0, vector_proj[0], vector_proj[1], angles='xy', scale_units='xy', scale=1, \n",
    "           color='green', width=0.01, label=f'Age component of User A')\n",
    "\n",
    "# Draw the \"shadow\" line (perpendicular from user_a to its projection)\n",
    "plt.plot([user_a[0], vector_proj[0]], [user_a[1], vector_proj[1]], \n",
    "         'gray', linestyle='--', alpha=0.7, label='Perpendicular drop')\n",
    "\n",
    "# Add annotations\n",
    "plt.annotate(f'Profile magnitude = {np.linalg.norm(user_a):.2f}', \n",
    "             xy=(user_a[0]/2, user_a[1]/2 + 0.05), fontsize=12, color='blue')\n",
    "plt.annotate(f'Age component = {scalar_proj:.2f}', \n",
    "             xy=(vector_proj[0]/2, -0.05), fontsize=12, color='green')\n",
    "\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 0.9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.title('User Profile Projection: Age Component of User A')\n",
    "plt.xlabel('Age (normalized)')\n",
    "plt.ylabel('Income (normalized)')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()\n"
   ],
   "id": "a01f72595033746f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's explore different user profile projection scenarios\n",
    "user_scenarios = [\n",
    "    (\"Similar users\", [0.6, 0.8], [0.8, 0.6]),  # Similar age/income profiles\n",
    "    (\"Age-focused vs Income-focused\", [0.9, 0.1], [0.1, 0.9]),  # Perpendicular preferences\n",
    "    (\"Opposite profiles\", [0.8, 0.9], [-0.4, -0.45]),  # Opposite directions (scaled)\n",
    "    (\"Young high-earner onto age axis\", [0.2, 0.9], [1.0, 0.0])  # Project onto pure age\n",
    "]\n",
    "\n",
    "print(\"=== USER PROFILE PROJECTION SCENARIOS ===\")\n",
    "for name, user_a, reference_dir in user_scenarios:\n",
    "    scalar_proj, vector_proj = project_vector(np.array(user_a), np.array(reference_dir))\n",
    "    dot_product = np.dot(user_a, reference_dir)\n",
    "\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  User profile = {user_a} (age_norm, income_norm)\")\n",
    "    print(f\"  Reference direction = {reference_dir}\")\n",
    "    print(f\"  Dot product = {dot_product:.3f}\")\n",
    "    print(f\"  Scalar projection = {scalar_proj:.3f}\")\n",
    "    print(f\"  Vector projection = [{vector_proj[0]:.3f}, {vector_proj[1]:.3f}]\")\n"
   ],
   "id": "62a9defbefa1812a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ML Application: Feature extraction using projection\n",
    "print(\"\\n=== ML APPLICATION: FEATURE EXTRACTION ===\")\n",
    "\n",
    "# Simulate some 2D data points (could be customer features, image features, etc.)\n",
    "data_points = np.array([\n",
    "    [2, 3],   # Customer 1: [age_normalized, income_normalized]\n",
    "    [1, 4],   # Customer 2\n",
    "    [3, 2],   # Customer 3\n",
    "    [4, 1],   # Customer 4\n",
    "    [1, 1]    # Customer 5\n",
    "])\n",
    "\n",
    "# Define a \"direction of interest\" (could be discovered by PCA, domain knowledge, etc.)\n",
    "direction = np.array([1, 1])  # Equal weight to age and income\n",
    "direction = direction / np.linalg.norm(direction)  # Normalize\n",
    "\n",
    "print(f\"Data points (customers): \\n{data_points}\")\n",
    "print(f\"Direction of interest: {direction}\")\n",
    "\n",
    "# Project all data points onto this direction\n",
    "projections = []\n",
    "for point in data_points:\n",
    "    scalar_proj, vector_proj = project_vector(point, direction)\n",
    "    projections.append(scalar_proj)\n",
    "\n",
    "projections = np.array(projections)\n",
    "print(f\"Projected values (1D features): {projections}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot original 2D data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data_points[:, 0], data_points[:, 1], c='blue', s=100)\n",
    "plt.quiver(0, 0, direction[0]*3, direction[1]*3, angles='xy', scale_units='xy', scale=1, \n",
    "           color='red', width=0.01, label='Projection direction')\n",
    "for i, point in enumerate(data_points):\n",
    "    plt.annotate(f'C{i+1}', xy=point, xytext=(5, 5), textcoords='offset points')\n",
    "plt.xlim(-0.5, 5)\n",
    "plt.ylim(-0.5, 5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.title('Original 2D Data')\n",
    "plt.xlabel('Feature 1 (e.g., Age)')\n",
    "plt.ylabel('Feature 2 (e.g., Income)')\n",
    "\n",
    "# Plot projected 1D data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(projections, np.zeros_like(projections), c='green', s=100)\n",
    "for i, proj in enumerate(projections):\n",
    "    plt.annotate(f'C{i+1}', xy=(proj, 0), xytext=(0, 10), textcoords='offset points')\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.title('Projected 1D Data')\n",
    "plt.xlabel('Projected Feature Value')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"‚Ä¢ Projection reduces dimensionality while preserving important information\")\n",
    "print(\"‚Ä¢ The projection direction determines what aspects of data we emphasize\")\n",
    "print(\"‚Ä¢ This is the foundation of techniques like PCA (Principal Component Analysis)\")\n",
    "print(\"‚Ä¢ In ML, we often project high-dimensional data to lower dimensions for visualization and efficiency\")\n"
   ],
   "id": "4cb4d5e2be171a92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîÑ Matrix Multiplication\n",
    "\n",
    "Matrix multiplication combines transformations. Remember: **order matters!** AB ‚â† BA in general.\n",
    "\n",
    "**Notation:** ‚â† means \"not equal to\"\n",
    "\n",
    "When we multiply an m√ón matrix A by an n√óp matrix B, we get an m√óp matrix C.\n"
   ],
   "id": "ba011956914f9640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Multiply matrices\n",
    "C = np.dot(A, B)\n",
    "print(\"A @ B =\\n\", C)\n",
    "\n",
    "# Let's verify that order matters\n",
    "C_reverse = np.dot(B, A)\n",
    "print(\"\\nB @ A =\\n\", C_reverse)\n",
    "print(f\"\\nAre they equal? {np.array_equal(C, C_reverse)}\")\n",
    "\n",
    "# Let's understand what matrix multiplication does geometrically\n",
    "# A matrix transforms vectors - let's see how\n",
    "test_vector = np.array([1, 0])  # Unit vector along x-axis\n",
    "transformed = A @ test_vector\n",
    "print(f\"\\nOriginal vector: {test_vector}\")\n",
    "print(f\"After transformation by A: {transformed}\")\n",
    "\n",
    "# The identity matrix does nothing (like multiplying by 1)\n",
    "I = np.eye(2)  # 2x2 identity matrix\n",
    "print(f\"\\nIdentity matrix:\\n{I}\")\n",
    "print(f\"I @ test_vector = {I @ test_vector}\")  # Should be unchanged"
   ],
   "id": "2750a24a213f3515",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üß† Visualizing Transformations",
   "id": "3c0a1e4d45fa9a96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_transform(A, title=\"Transformation\"):\n",
    "    grid = np.array([[x, y] for x in range(-2, 3) for y in range(-2, 3)])\n",
    "    transformed = grid @ A.T\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.quiver(grid[:, 0], grid[:, 1], transformed[:, 0] - grid[:, 0], transformed[:, 1] - grid[:, 1], angles='xy', scale_units='xy', scale=1, color='r')\n",
    "    plt.scatter(grid[:, 0], grid[:, 1], color='blue')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='gray', lw=1)\n",
    "    plt.axvline(0, color='gray', lw=1)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()\n",
    "\n",
    "plot_transform(np.array([[2, 0], [0, 1]]), title=\"Horizontal Stretch\")"
   ],
   "id": "fc569e2b9046bf91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚úÖ Summary Quiz & Checklist\n",
    "\n",
    "### Quiz Questions\n",
    "1. **What does matrix multiplication represent geometrically?**\n",
    "   > Matrix multiplication represents the composition of linear transformations. Each matrix transforms space in some way (stretch, rotate, reflect, etc.), and multiplying matrices combines these transformations.\n",
    "\n",
    "2. **What happens when you dot a vector with itself?**\n",
    "   > You get the squared magnitude (length) of the vector: **v** ¬∑ **v** = ||**v**||¬≤\n",
    "\n",
    "3. **Which operations preserve direction?**\n",
    "   > Scalar multiplication by positive numbers preserves direction. Matrix transformations may or may not preserve direction depending on the matrix.\n",
    "\n",
    "4. **Why does AB ‚â† BA in general?**\n",
    "   > Because matrix multiplication represents composition of transformations, and the order of transformations matters. Rotating then stretching gives a different result than stretching then rotating.\n",
    "\n",
    "### Self-Assessment Checklist\n",
    "Check off each item as you master it:\n",
    "\n",
    "**Vector Fundamentals:**\n",
    "- [ ] I understand what vectors are: mathematical objects with magnitude and direction\n",
    "- [ ] I can explain why vectors are central to machine learning (data representation, similarity, transformations)\n",
    "- [ ] I can give concrete examples of how different data types become vectors\n",
    "- [ ] I can visualize vectors as arrows in space and interpret their geometric meaning\n",
    "\n",
    "**Vector Relationships:**\n",
    "- [ ] I understand what angles between vectors represent (similarity/alignment)\n",
    "- [ ] I can explain why small angles mean high similarity and large angles mean low similarity\n",
    "- [ ] I can compute and interpret dot products as measures of vector alignment\n",
    "- [ ] I can connect vector similarity to real ML applications (recommendations, document analysis, etc.)\n",
    "\n",
    "**Mathematical Operations:**\n",
    "- [ ] I can compute a dot product and explain its geometric meaning\n",
    "- [ ] I can multiply two matrices and describe the geometric effect\n",
    "- [ ] I can visualize matrix transformations on a 2D grid\n",
    "- [ ] I can explain why AB ‚â† BA (order matters in matrix multiplication)\n",
    "- [ ] I understand the role of the identity matrix\n",
    "\n",
    "**ML Connections:**\n",
    "- [ ] I can connect these concepts to machine learning applications\n",
    "- [ ] I understand how vectors represent data points in feature spaces\n",
    "- [ ] I can explain how ML algorithms use vector operations to find patterns\n",
    "\n",
    "### üîó Next Steps\n",
    "- Review the [companion theory file](01_linear_algebra_intro.md) for deeper mathematical insights\n",
    "- Practice with different transformation matrices\n",
    "- Think about how these concepts might apply to neural networks (hint: they're everywhere!)\n",
    "\n",
    "### üí° Key Takeaways\n",
    "- **Vectors**: Quantities with direction and magnitude\n",
    "- **Matrices**: Functions that transform space\n",
    "- **Dot Product**: Measures alignment between vectors\n",
    "- **Matrix Multiplication**: Combines transformations (order matters!)\n",
    "- **Geometric Intuition**: Always try to visualize what's happening in space\n"
   ],
   "id": "c55049890b15eaf2"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
