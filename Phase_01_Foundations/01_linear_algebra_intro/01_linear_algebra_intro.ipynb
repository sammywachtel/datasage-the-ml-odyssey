{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01: Linear Algebra Intro\n",
    "\n",
    "Welcome to your first deep dive! Today weâ€™ll build intuition and hands-on experience with vectors, matrices, and their operationsâ€”the foundation of almost every ML algorithm.\n",
    "\n",
    "> ðŸ’¡ **Companion Reading**: This notebook pairs with [01_linear_algebra_intro.md](01_linear_algebra_intro.md) for deeper mathematical insights, analogies, and tutor guidance.\n",
    "\n",
    "## ðŸŽ¯ Objectives\n",
    "- Understand what vectors and matrices are conceptually and computationally\n",
    "- Learn how to compute dot products and matrix multiplication\n",
    "- Visualize geometric interpretations of linear transformations\n",
    "- Explore how these concepts relate to ML models\n",
    "- Build intuition through hands-on coding and visualization"
   ],
   "id": "3a1723715fb88362"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ“Œ Vectors and Basic Operations\n",
    "Letâ€™s start by defining vectors and doing some operations."
   ],
   "id": "3b49c5e9d7bcdd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "v1 = np.array([1, 2])\n",
    "v2 = np.array([3, 4])\n",
    "\n",
    "# Vector addition and scalar multiplication\n",
    "print(\"v1 + v2 =\", v1 + v2)\n",
    "print(\"2 * v1 =\", 2 * v1)"
   ],
   "id": "2c89547928944523"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ”¢ Dot Product\n",
    "The dot product tells us how aligned two vectors are. Mathematically: **a** Â· **b** = ||a|| ||b|| cos(Î¸)\n",
    "\n",
    "This means:\n",
    "- When vectors point in the same direction (Î¸ = 0Â°): cos(0Â°) = 1, maximum dot product\n",
    "- When vectors are perpendicular (Î¸ = 90Â°): cos(90Â°) = 0, dot product = 0\n",
    "- When vectors point in opposite directions (Î¸ = 180Â°): cos(180Â°) = -1, negative dot product\n"
   ],
   "id": "8bf81d37f9b100bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute dot product\n",
    "dot = np.dot(v1, v2)\n",
    "print(\"Dot product of v1 and v2:\", dot)\n",
    "\n",
    "# Let's explore the geometric meaning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the vectors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1, color='blue', label='v1', width=0.005)\n",
    "plt.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1, color='red', label='v2', width=0.005)\n",
    "\n",
    "# Calculate angle between vectors\n",
    "angle = np.arccos(dot / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "print(f\"Angle between vectors: {np.degrees(angle):.1f} degrees\")\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1, 5)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title(f'Vectors v1 and v2 (dot product = {dot})')\n",
    "plt.show()\n",
    "\n",
    "# Special case: dot product with itself gives squared magnitude\n",
    "v1_squared = np.dot(v1, v1)\n",
    "v1_magnitude_squared = np.linalg.norm(v1)**2\n",
    "print(f\"v1 Â· v1 = {v1_squared}\")\n",
    "print(f\"||v1||Â² = {v1_magnitude_squared}\")\n",
    "print(\"They're equal! This is always true.\")\n"
   ],
   "id": "ceb7d000ad091305"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Quiz:**\n",
    "What is the geometric meaning of a dot product?\n",
    "- A. The angle between vectors\n",
    "- B. The projection of one vector onto another  \n",
    "- C. A measure of similarity/alignment\n",
    "- D. All of the above\n",
    "\n",
    "> **Answer**: D. All of the above! The dot product encodes the angle between vectors, can be used to compute projections, and serves as a similarity measure."
   ],
   "id": "b96238374ef021d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ”„ Matrix Multiplication\n",
    "\n",
    "Matrix multiplication combines transformations. Remember: **order matters!** AB â‰  BA in general.\n",
    "\n",
    "When we multiply an mÃ—n matrix A by an nÃ—p matrix B, we get an mÃ—p matrix C.\n"
   ],
   "id": "d5b2577040af2351"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Multiply matrices\n",
    "C = np.dot(A, B)\n",
    "print(\"A @ B =\\n\", C)\n",
    "\n",
    "# Let's verify that order matters\n",
    "C_reverse = np.dot(B, A)\n",
    "print(\"\\nB @ A =\\n\", C_reverse)\n",
    "print(f\"\\nAre they equal? {np.array_equal(C, C_reverse)}\")\n",
    "\n",
    "# Let's understand what matrix multiplication does geometrically\n",
    "# A matrix transforms vectors - let's see how\n",
    "test_vector = np.array([1, 0])  # Unit vector along x-axis\n",
    "transformed = A @ test_vector\n",
    "print(f\"\\nOriginal vector: {test_vector}\")\n",
    "print(f\"After transformation by A: {transformed}\")\n",
    "\n",
    "# The identity matrix does nothing (like multiplying by 1)\n",
    "I = np.eye(2)  # 2x2 identity matrix\n",
    "print(f\"\\nIdentity matrix:\\n{I}\")\n",
    "print(f\"I @ test_vector = {I @ test_vector}\")  # Should be unchanged"
   ],
   "id": "8dd5e0c7c04aa55b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸ§  Visualizing Transformations",
   "id": "6183e1f22c200bca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_transform(A, title=\"Transformation\"):\n",
    "    grid = np.array([[x, y] for x in range(-2, 3) for y in range(-2, 3)])\n",
    "    transformed = grid @ A.T\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.quiver(grid[:, 0], grid[:, 1], transformed[:, 0] - grid[:, 0], transformed[:, 1] - grid[:, 1], angles='xy', scale_units='xy', scale=1, color='r')\n",
    "    plt.scatter(grid[:, 0], grid[:, 1], color='blue')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='gray', lw=1)\n",
    "    plt.axvline(0, color='gray', lw=1)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()\n",
    "\n",
    "plot_transform(np.array([[2, 0], [0, 1]]), title=\"Horizontal Stretch\")"
   ],
   "id": "a225e0a5f11af4fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## âœ… Summary Quiz & Checklist\n",
    "\n",
    "### Quiz Questions\n",
    "1. **What does matrix multiplication represent geometrically?**\n",
    "   > Matrix multiplication represents the composition of linear transformations. Each matrix transforms space in some way (stretch, rotate, reflect, etc.), and multiplying matrices combines these transformations.\n",
    "\n",
    "2. **What happens when you dot a vector with itself?**\n",
    "   > You get the squared magnitude (length) of the vector: **v** Â· **v** = ||**v**||Â²\n",
    "\n",
    "3. **Which operations preserve direction?**\n",
    "   > Scalar multiplication by positive numbers preserves direction. Matrix transformations may or may not preserve direction depending on the matrix.\n",
    "\n",
    "4. **Why does AB â‰  BA in general?**\n",
    "   > Because matrix multiplication represents composition of transformations, and the order of transformations matters. Rotating then stretching gives a different result than stretching then rotating.\n",
    "\n",
    "### Self-Assessment Checklist\n",
    "Check off each item as you master it:\n",
    "\n",
    "- [ ] I understand what vectors and matrices are conceptually\n",
    "- [ ] I can compute a dot product and explain its geometric meaning\n",
    "- [ ] I can multiply two matrices and describe the geometric effect\n",
    "- [ ] I can visualize matrix transformations on a 2D grid\n",
    "- [ ] I can explain why AB â‰  BA (order matters in matrix multiplication)\n",
    "- [ ] I understand the role of the identity matrix\n",
    "- [ ] I can connect these concepts to machine learning applications\n",
    "\n",
    "### ðŸ”— Next Steps\n",
    "- Review the [companion theory file](01_linear_algebra_intro.md) for deeper mathematical insights\n",
    "- Practice with different transformation matrices\n",
    "- Think about how these concepts might apply to neural networks (hint: they're everywhere!)\n",
    "\n",
    "### ðŸ’¡ Key Takeaways\n",
    "- **Vectors**: Quantities with direction and magnitude\n",
    "- **Matrices**: Functions that transform space\n",
    "- **Dot Product**: Measures alignment between vectors\n",
    "- **Matrix Multiplication**: Combines transformations (order matters!)\n",
    "- **Geometric Intuition**: Always try to visualize what's happening in space\n"
   ],
   "id": "624cc0cb0c55051a"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
