{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e82a98ce",
   "metadata": {},
   "source": [
    "# 04: Python & Tooling for Machine Learning\n",
    "\n",
    "Welcome to your ML toolkit! Today we'll master the essential Python libraries that form the backbone of every machine learning project. These tools will be your daily companions in the ML world.\n",
    "\n",
    "> ðŸ’¡ **Companion Reading**: This notebook pairs with [04_python_tooling.md](04_python_tooling.md) for deeper insights, best practices, and additional guidance.\n",
    "\n",
    "## ðŸŽ¯ Objectives\n",
    "- Master data manipulation using pandas and NumPy for ML workflows\n",
    "- Create insightful visualizations using matplotlib and seaborn\n",
    "- Load, explore, and understand real-world datasets\n",
    "- Perform data cleaning and feature engineering for machine learning\n",
    "- Build and evaluate simple models using scikit-learn\n",
    "- Develop practical skills for the entire ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45785e09",
   "metadata": {},
   "source": [
    "## ðŸ“Š Working with DataFrames\n",
    "\n",
    "Pandas DataFrames are like supercharged spreadsheets. They're the primary way we handle structured data in machine learning projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae3ab6ef",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load sample data - restaurant tips dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    "\n",
    "print(\"ðŸ“‹ Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape} (rows, columns)\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nðŸ“Š First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nðŸ” Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Quick Info:\")\n",
    "print(df.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cca341ed",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Exploratory Data Analysis\n",
    "\n",
    "Understanding your data is the first step in any ML project. Let's explore what we're working with!\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a93cb8c1",
   "metadata": {},
   "source": [
    "# Summary statistics for numerical columns\n",
    "print(\"ðŸ“Š Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nðŸ·ï¸ Categorical Variables:\")\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nâ“ Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values! ðŸŽ‰\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92e76f6a",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Data Cleaning & Feature Engineering\n",
    "\n",
    "Raw data is rarely ready for modeling. Let's clean and enhance our dataset!\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "14b2c1b3",
   "metadata": {},
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Feature engineering: create tip percentage\n",
    "df_clean['tip_percent'] = 100 * df_clean['tip'] / df_clean['total_bill']\n",
    "\n",
    "# Create additional features that might be useful\n",
    "df_clean['party_size_category'] = pd.cut(df_clean['size'], \n",
    "                                        bins=[0, 2, 4, float('inf')], \n",
    "                                        labels=['Small (1-2)', 'Medium (3-4)', 'Large (5+)'])\n",
    "\n",
    "# Convert categorical variables to numerical (for modeling later)\n",
    "df_clean['sex_encoded'] = df_clean['sex'].map({'Male': 1, 'Female': 0})\n",
    "df_clean['smoker_encoded'] = df_clean['smoker'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"ðŸ”§ Feature Engineering Results:\")\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"Enhanced columns: {len(df_clean.columns)}\")\n",
    "print(\"\\nðŸ“Š New features preview:\")\n",
    "print(df_clean[['total_bill', 'tip', 'tip_percent', 'party_size_category']].head())\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Tip percentage statistics:\")\n",
    "print(f\"Mean: {df_clean['tip_percent'].mean():.1f}%\")\n",
    "print(f\"Median: {df_clean['tip_percent'].median():.1f}%\")\n",
    "print(f\"Range: {df_clean['tip_percent'].min():.1f}% - {df_clean['tip_percent'].max():.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90b6b50a",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Data Visualization\n",
    "\n",
    "Visualization is crucial for understanding patterns in your data. Let's create insightful plots that reveal relationships and trends!\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "97f5b065",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create a comprehensive visualization dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Scatter plot: Tips vs Total Bill\n",
    "sns.scatterplot(data=df_clean, x='total_bill', y='tip', hue='sex', ax=axes[0,0])\n",
    "axes[0,0].set_title(\"Tips vs. Total Bill by Gender\")\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribution of tip percentages\n",
    "sns.histplot(data=df_clean, x='tip_percent', bins=20, ax=axes[0,1])\n",
    "axes[0,1].set_title(\"Distribution of Tip Percentages\")\n",
    "axes[0,1].axvline(df_clean['tip_percent'].mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {df_clean[\"tip_percent\"].mean():.1f}%')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Box plot: Tips by day and time\n",
    "sns.boxplot(data=df_clean, x='day', y='tip_percent', hue='time', ax=axes[1,0])\n",
    "axes[1,0].set_title(\"Tip Percentage by Day and Time\")\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Correlation heatmap\n",
    "numeric_cols = ['total_bill', 'tip', 'size', 'tip_percent']\n",
    "correlation_matrix = df_clean[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
    "axes[1,1].set_title(\"Feature Correlation Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print insights\n",
    "print(\"ðŸ” Key Insights from Visualizations:\")\n",
    "print(f\"1. Strong positive correlation between total_bill and tip: {correlation_matrix.loc['total_bill', 'tip']:.3f}\")\n",
    "print(f\"2. Average tip percentage: {df_clean['tip_percent'].mean():.1f}%\")\n",
    "print(f\"3. Tip percentage varies by day and time\")\n",
    "print(f\"4. Party size shows moderate correlation with total bill\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "692abb07",
   "metadata": {},
   "source": [
    "## ðŸ” Machine Learning with Scikit-learn\n",
    "\n",
    "Now let's build our first machine learning model! We'll predict tip amounts based on bill characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "04b2ecaa",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare features and target\n",
    "# Using multiple features for better prediction\n",
    "X = df_clean[['total_bill', 'size', 'sex_encoded', 'smoker_encoded']]\n",
    "y = df_clean['tip']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"ðŸ¤– Model Performance:\")\n",
    "print(f\"RÂ² Score: {r2:.3f} (higher is better, max = 1.0)\")\n",
    "print(f\"Mean Squared Error: {mse:.3f}\")\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mse):.3f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Model Coefficients:\")\n",
    "feature_names = ['Total Bill', 'Party Size', 'Gender (Male=1)', 'Smoker (Yes=1)']\n",
    "for name, coef in zip(feature_names, model.coef_):\n",
    "    print(f\"{name}: {coef:.3f}\")\n",
    "print(f\"Intercept: {model.intercept_:.3f}\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Tips')\n",
    "plt.ylabel('Predicted Tips')\n",
    "plt.title('Predictions vs Actual')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "importance = np.abs(model.coef_)\n",
    "plt.barh(feature_names, importance)\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.title('Feature Importance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Model Insights:\")\n",
    "print(\"- Total bill is the strongest predictor of tip amount\")\n",
    "print(\"- Party size also influences tip amount\")\n",
    "print(\"- Gender and smoking status have smaller effects\")\n",
    "print(f\"- Model explains {r2*100:.1f}% of the variance in tip amounts\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5125ed2c",
   "metadata": {},
   "source": [
    "## âœ… Summary Quiz & Checklist\n",
    "\n",
    "### Quiz Questions\n",
    "1. **What does `df.describe()` show you?**\n",
    "   > `df.describe()` provides summary statistics for numerical columns including count, mean, standard deviation, minimum, maximum, and quartiles (25%, 50%, 75%). It's essential for understanding the distribution and range of your data.\n",
    "\n",
    "2. **Why is feature engineering (like tip percentage) helpful?**\n",
    "   > Feature engineering creates more meaningful variables for machine learning. Tip percentage is more informative than raw tip amount because it normalizes for bill size, making it easier for models to learn patterns and make better predictions.\n",
    "\n",
    "3. **What does the `.fit()` method do in scikit-learn?**\n",
    "   > The `.fit()` method trains the machine learning model on the provided training data. It learns the patterns and relationships between features (X) and target variable (y), adjusting the model's internal parameters.\n",
    "\n",
    "4. **Why do we split data into training and testing sets?**\n",
    "   > To evaluate how well our model generalizes to unseen data. Training on all data and testing on the same data would give overly optimistic results that don't reflect real-world performance.\n",
    "\n",
    "### Self-Assessment Checklist\n",
    "Check off each item as you master it:\n",
    "\n",
    "- [ ] I can load and inspect datasets with pandas\n",
    "- [ ] I can perform exploratory data analysis to understand my data\n",
    "- [ ] I can clean data and handle missing values\n",
    "- [ ] I can create new features through feature engineering\n",
    "- [ ] I can create informative visualizations with matplotlib and seaborn\n",
    "- [ ] I can interpret correlation matrices and statistical summaries\n",
    "- [ ] I can build and evaluate machine learning models with scikit-learn\n",
    "- [ ] I understand the importance of train/test splits\n",
    "- [ ] I can interpret model coefficients and performance metrics\n",
    "\n",
    "### ðŸ”— Next Steps\n",
    "- Review the [companion theory file](04_python_tooling.md) for deeper insights and best practices\n",
    "- Practice with different datasets and visualization types\n",
    "- Experiment with other scikit-learn models (e.g., decision trees, random forests)\n",
    "- Learn about cross-validation and more advanced evaluation techniques\n",
    "\n",
    "### ðŸ’¡ Key Takeaways\n",
    "- **Pandas**: Your go-to tool for data manipulation and analysis\n",
    "- **Visualization**: Essential for understanding data patterns and relationships\n",
    "- **Feature Engineering**: Often more important than the choice of algorithm\n",
    "- **Scikit-learn**: Provides a consistent interface for machine learning\n",
    "- **Evaluation**: Always test your model on unseen data to assess real performance\n",
    "- **Workflow**: Load â†’ Explore â†’ Clean â†’ Engineer â†’ Model â†’ Evaluate\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
