# 03: Calculus for Machine Learning

## ğŸ“˜ Overview
Calculus provides the mathematical tools to understand how models learn and optimize. This file complements the notebook with derivations, analogies, and instructional support.

> ğŸ’» **Hands-On Practice**: This theory guide pairs with [03_calculus_for_ml.ipynb](03_calculus_for_ml.ipynb) for interactive gradient descent demonstrations and optimization exercises.

---

## ğŸ§  Key Concepts

- **Derivative**: Measures rate of change. Tells us how steep a function is at a point.
- **Gradient**: A vector of partial derivatives â€” shows the direction of steepest ascent.
- **Chain Rule**: Used to differentiate nested functions.
- **Gradient Descent**: An iterative algorithm that moves in the direction opposite the gradient to minimize a cost function.

---

## ğŸ” Mathematical Derivations

### Derivative of a Quadratic

$$
f(x) = (x - 3)^2 \\
f'(x) = 2(x - 3)
$$

### Chain Rule Example

If $f(g(x)) = (2x + 1)^2$:

$$
f'(x) = 2(2x + 1) \cdot 2 = 4(2x + 1)
$$

---

## ğŸ¨ Analogies & Intuition

- **Derivative**: Like measuring the slope of a hill you're standing on.
- **Gradient Descent**: A hiker taking steps downhill to reach the lowest point of a valley.
- **Learning Rate**: Step size â€” too small = slow, too big = overshoot or bounce.

---

## ğŸ¯ Tutor Instructions

### Teaching Prompts
- â€œCan you describe in your own words what a derivative tells you about a function?â€
- â€œWhat happens if the gradient is zero?â€
- â€œLetâ€™s graph a loss curve. Show me where the gradient would be positive or negative.â€

### Pop Quiz Strategy
- Revisit earlier knowledge: â€œWhere else have we seen slopes before?â€
- Challenge: â€œChange the learning rate. What happens to convergence?â€

---

## ğŸ§ª Quiz Questions (with Answers)

**Q1.** What does a derivative represent?  
> âœ… The slope or rate of change of a function at a point

**Q2.** What does the gradient represent in ML?  
> âœ… The vector of slopes for each input dimension â€” shows how to adjust weights

**Q3.** What is the purpose of the learning rate in gradient descent?  
> âœ… Controls how big a step we take in the direction of the negative gradient

**Q4.** What happens when you use too large a learning rate?  
> âŒ The algorithm may diverge or oscillate

---

## âœ… Summary Checklist

- [ ] I understand how to compute and interpret a derivative
- [ ] I understand what a gradient is in multiple dimensions
- [ ] I can apply the chain rule
- [ ] I can visualize and explain gradient descent
- [ ] I know how learning rate affects convergence

---
